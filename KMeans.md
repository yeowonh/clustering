## K-Means 알고리즘

가장 단순하고 빠른 군집화 방법 중 하나.

군집 중심점(centroid)이라는 특정한 지점을 선택해 중심에 가장 가까운 포인트들을 선택하는 군집화 기법

![K 평균 군집분류 (K-Means Classification) 알고리즘 원리 이해하기 :: R 모조리 정복하기](https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99F470335A13DC8F02)

> https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99F470335A13DC8F02



centroid의 평균 지점으로 이동 -> 이동된 중심점에서 다시 가까운 포인트를 선택해 할당

-> 다시 평균 지점으로 이동

더 이상 중심점의 이동이 없을 경우 반복을 멈추고 해당 중심점에 속하는 데이터 포인트들을 군집화.

즉, 중심점 이동 시 데이터들의 소속 변경이 없으면 군집화 완료


### 수식 표현

목적함수
$$
J=∑_{k=1}^{K}∑_{i∈C_k}d(xi,μk)=∑_{i=1}^{N}min_{μ_j∈C}(||xi−μj||2)
$$

* K : 군집의 개수
* C<sub>k</sub> : k번째 군집에 속하는 데이터의 집합
* u<sub>k</sub> : k번째 군집의 중심위치(centroid)
* d = x<sub>i</sub>, u<sub>k</sub> 두 데이터 사이의 거리 혹은 비유사도로 정의


1. 임의의 중심위치 μk(k=1,…,K)μk(k=1,…,K)를 고른다. 보통 데이터 표본 중에서 KK개를 선택한다.
2. 모든 데이터 xi(i=1,…,N)xi(i=1,…,N)에서 각각의 중심위치 μkμk까지의 거리를 계산한다.
3. 각 데이터에서 가장 가까운 중심위치를 선택하여 각 데이터가 속하는 군집을 정한다.
4. 각 군집에 대해 중심위치 μk를 다시 계산한다.
5. 2 ~ 4를 반복한다.

* 장점
  - 일반적인 군집화에서 가장 많이 활용되는 알고리즘
  - 알고리즘이 쉽고 간결

* 단점
  - 거리 기반 알고리즘으로 속성이 많을 경우 군집화 정확도가 떨어짐
  - 반복횟수가 많을 경우 수행 시간 매우 느려짐
  - 몇 개의 군집을 선택할지 가이드하기 어렵다
  - 군집화 결과가 초기 중심 위치에 따라 달라질 수 있음


### 사이킷런 KMeans 클래스

`class sklearn.cluster.KMeans()`

* `n_clusters`: 군집의 갯수(=군집 중심점의 개수) **가장 중요**
* `init`: 초기화 방법. `"random"`이면 무작위, `"k-means++"`이면 K-평균++ 방법. 또는 각 데이터의 군집 라벨.
* `n_init`: 초기 중심위치 시도 횟수. 디폴트는 10이고 10개의 무작위 중심위치 목록 중 가장 좋은 값을 선택한다.
* `max_iter`: 최대 반복 횟수.
* `random_state`: 시드값
